{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:33.751181Z","iopub.execute_input":"2023-07-22T11:42:33.751630Z","iopub.status.idle":"2023-07-22T11:42:38.283407Z","shell.execute_reply.started":"2023-07-22T11:42:33.751587Z","shell.execute_reply":"2023-07-22T11:42:38.282329Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model_nm = 'distilbert-base-uncased'","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:38.285364Z","iopub.execute_input":"2023-07-22T11:42:38.286066Z","iopub.status.idle":"2023-07-22T11:42:38.291297Z","shell.execute_reply.started":"2023-07-22T11:42:38.286030Z","shell.execute_reply":"2023-07-22T11:42:38.290226Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForMaskedLM.from_pretrained(model_nm)\ntokenizer = AutoTokenizer.from_pretrained(model_nm)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:38.292897Z","iopub.execute_input":"2023-07-22T11:42:38.293278Z","iopub.status.idle":"2023-07-22T11:42:50.448310Z","shell.execute_reply.started":"2023-07-22T11:42:38.293246Z","shell.execute_reply":"2023-07-22T11:42:50.447309Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5ca28c937a640cd95605c50e3f6f53e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b91a5644f524e01978b43714888d354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea874545c90344db821ab5810ed4bf17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a12f88f6af44d33bf9992282fa2639a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df8ac2450e714c01b4ec6a3a01fc4821"}},"metadata":{}}]},{"cell_type":"code","source":"inputs = tokenizer('This is a great [MASK]', return_tensors='pt')\ninputs","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:50.451172Z","iopub.execute_input":"2023-07-22T11:42:50.451528Z","iopub.status.idle":"2023-07-22T11:42:50.466868Z","shell.execute_reply.started":"2023-07-22T11:42:50.451495Z","shell.execute_reply":"2023-07-22T11:42:50.465919Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 101, 2023, 2003, 1037, 2307,  103,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"},"metadata":{}}]},{"cell_type":"code","source":"token_logits = model(**inputs).logits","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:50.468421Z","iopub.execute_input":"2023-07-22T11:42:50.468743Z","iopub.status.idle":"2023-07-22T11:42:50.631101Z","shell.execute_reply.started":"2023-07-22T11:42:50.468713Z","shell.execute_reply":"2023-07-22T11:42:50.628996Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"token_logits.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:50.637923Z","iopub.execute_input":"2023-07-22T11:42:50.638663Z","iopub.status.idle":"2023-07-22T11:42:50.650655Z","shell.execute_reply.started":"2023-07-22T11:42:50.638629Z","shell.execute_reply":"2023-07-22T11:42:50.649432Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 7, 30522])"},"metadata":{}}]},{"cell_type":"code","source":"mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\nmask_token_index","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:50.651991Z","iopub.execute_input":"2023-07-22T11:42:50.652921Z","iopub.status.idle":"2023-07-22T11:42:50.667602Z","shell.execute_reply.started":"2023-07-22T11:42:50.652888Z","shell.execute_reply":"2023-07-22T11:42:50.665307Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"tensor([5])"},"metadata":{}}]},{"cell_type":"code","source":"mask_token_logits = token_logits[0, mask_token_index]\nmask_token_logits ","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:50.668867Z","iopub.execute_input":"2023-07-22T11:42:50.671305Z","iopub.status.idle":"2023-07-22T11:42:50.702056Z","shell.execute_reply.started":"2023-07-22T11:42:50.671143Z","shell.execute_reply":"2023-07-22T11:42:50.701128Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"tensor([[-7.1287, -7.0408, -7.4466,  ..., -6.2678, -7.3546, -2.8264]],\n       grad_fn=<IndexBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"top_5_tokens = torch.topk(mask_token_logits, 10).indices[0].tolist()\ntop_5_tokens","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:50.709179Z","iopub.execute_input":"2023-07-22T11:42:50.712273Z","iopub.status.idle":"2023-07-22T11:42:50.729414Z","shell.execute_reply.started":"2023-07-22T11:42:50.712238Z","shell.execute_reply":"2023-07-22T11:42:50.727829Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[999, 1012, 3066, 6172, 1025, 1029, 3112, 6547, 2518, 3861]"},"metadata":{}}]},{"cell_type":"code","source":"for i in top_5_tokens:\n    print(tokenizer.decode([i]))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:50.741588Z","iopub.execute_input":"2023-07-22T11:42:50.744464Z","iopub.status.idle":"2023-07-22T11:42:50.753760Z","shell.execute_reply.started":"2023-07-22T11:42:50.744431Z","shell.execute_reply":"2023-07-22T11:42:50.752618Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"!\n.\ndeal\nadventure\n;\n?\nsuccess\nmystery\nthing\npicture\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:50.757404Z","iopub.execute_input":"2023-07-22T11:42:50.759586Z","iopub.status.idle":"2023-07-22T11:42:51.360407Z","shell.execute_reply.started":"2023-07-22T11:42:50.759545Z","shell.execute_reply":"2023-07-22T11:42:51.359339Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"imdb_dataset = load_dataset('imdb')\nimdb_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:42:51.364906Z","iopub.execute_input":"2023-07-22T11:42:51.367551Z","iopub.status.idle":"2023-07-22T11:43:36.362045Z","shell.execute_reply.started":"2023-07-22T11:42:51.367513Z","shell.execute_reply":"2023-07-22T11:43:36.361079Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"792d49901a1f4f489f6e05dca7a8eb9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0797be04bf9542469790290596c1046f"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0398a4c8c7f421d8c83a65e6bb7f4c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2ff0dd7dff64f359cae8b61b03d48ed"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['text', 'label'],\n        num_rows: 50000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"imdb_dataset['train'][0]['text']","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.363740Z","iopub.execute_input":"2023-07-22T11:43:36.364394Z","iopub.status.idle":"2023-07-22T11:43:36.371392Z","shell.execute_reply.started":"2023-07-22T11:43:36.364359Z","shell.execute_reply":"2023-07-22T11:43:36.370449Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'"},"metadata":{}}]},{"cell_type":"code","source":"result = tokenizer(imdb_dataset['train'][0]['text'])\nresult","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.373171Z","iopub.execute_input":"2023-07-22T11:43:36.373898Z","iopub.status.idle":"2023-07-22T11:43:36.385577Z","shell.execute_reply.started":"2023-07-22T11:43:36.373849Z","shell.execute_reply":"2023-07-22T11:43:36.384324Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"len(result['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.387118Z","iopub.execute_input":"2023-07-22T11:43:36.387688Z","iopub.status.idle":"2023-07-22T11:43:36.394145Z","shell.execute_reply.started":"2023-07-22T11:43:36.387655Z","shell.execute_reply":"2023-07-22T11:43:36.393168Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"363"},"metadata":{}}]},{"cell_type":"code","source":"len(result.word_ids())","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.395625Z","iopub.execute_input":"2023-07-22T11:43:36.396266Z","iopub.status.idle":"2023-07-22T11:43:36.404066Z","shell.execute_reply.started":"2023-07-22T11:43:36.396234Z","shell.execute_reply":"2023-07-22T11:43:36.403058Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"363"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.is_fast","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.405554Z","iopub.execute_input":"2023-07-22T11:43:36.406255Z","iopub.status.idle":"2023-07-22T11:43:36.414712Z","shell.execute_reply.started":"2023-07-22T11:43:36.406218Z","shell.execute_reply":"2023-07-22T11:43:36.413668Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"result.word_ids(0) == result.word_ids()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.416128Z","iopub.execute_input":"2023-07-22T11:43:36.417213Z","iopub.status.idle":"2023-07-22T11:43:36.426244Z","shell.execute_reply.started":"2023-07-22T11:43:36.417182Z","shell.execute_reply":"2023-07-22T11:43:36.425368Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"result['word_ids'] = result.word_ids()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.427548Z","iopub.execute_input":"2023-07-22T11:43:36.428009Z","iopub.status.idle":"2023-07-22T11:43:36.434063Z","shell.execute_reply.started":"2023-07-22T11:43:36.427978Z","shell.execute_reply":"2023-07-22T11:43:36.433060Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"result","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.435397Z","iopub.execute_input":"2023-07-22T11:43:36.436186Z","iopub.status.idle":"2023-07-22T11:43:36.445189Z","shell.execute_reply.started":"2023-07-22T11:43:36.436152Z","shell.execute_reply":"2023-07-22T11:43:36.444321Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'word_ids': [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 143, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 216, 217, 218, 218, 219, 220, 221, 222, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 272, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, None]}"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_func(item):\n    result = tokenizer(item['text'])\n    if tokenizer.is_fast:\n        result['word_ids'] = [result.word_ids(i) for i in range(len(result.input_ids))]\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.447455Z","iopub.execute_input":"2023-07-22T11:43:36.448209Z","iopub.status.idle":"2023-07-22T11:43:36.454269Z","shell.execute_reply.started":"2023-07-22T11:43:36.448177Z","shell.execute_reply":"2023-07-22T11:43:36.453543Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tokenizer.model_max_length","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.455530Z","iopub.execute_input":"2023-07-22T11:43:36.456551Z","iopub.status.idle":"2023-07-22T11:43:36.465773Z","shell.execute_reply.started":"2023-07-22T11:43:36.456519Z","shell.execute_reply":"2023-07-22T11:43:36.464831Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"512"},"metadata":{}}]},{"cell_type":"code","source":"tokenize_dataset = imdb_dataset.map(tokenize_func, batched = True, remove_columns=['text', 'label'])\ntokenize_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:43:36.467536Z","iopub.execute_input":"2023-07-22T11:43:36.467867Z","iopub.status.idle":"2023-07-22T11:45:12.080080Z","shell.execute_reply.started":"2023-07-22T11:43:36.467836Z","shell.execute_reply":"2023-07-22T11:45:12.078986Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75e5128284b44ca9af43230ceb7877da"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eff1547d41e462599d994a83c659413"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49936c9812d341f4bd69a8c5c922a36a"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids'],\n        num_rows: 50000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"chunk_size = 128","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.081728Z","iopub.execute_input":"2023-07-22T11:45:12.082088Z","iopub.status.idle":"2023-07-22T11:45:12.091813Z","shell.execute_reply.started":"2023-07-22T11:45:12.082054Z","shell.execute_reply":"2023-07-22T11:45:12.090779Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"samples = tokenize_dataset['train'][:3]\nlen(samples)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.092999Z","iopub.execute_input":"2023-07-22T11:45:12.093285Z","iopub.status.idle":"2023-07-22T11:45:12.317355Z","shell.execute_reply.started":"2023-07-22T11:45:12.093262Z","shell.execute_reply":"2023-07-22T11:45:12.316214Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"for idx, sample in enumerate(samples['input_ids']):\n    print(idx, len(sample))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.319107Z","iopub.execute_input":"2023-07-22T11:45:12.319478Z","iopub.status.idle":"2023-07-22T11:45:12.328010Z","shell.execute_reply.started":"2023-07-22T11:45:12.319446Z","shell.execute_reply":"2023-07-22T11:45:12.327089Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"0 363\n1 304\n2 133\n","output_type":"stream"}]},{"cell_type":"code","source":"samples.keys()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.329595Z","iopub.execute_input":"2023-07-22T11:45:12.330437Z","iopub.status.idle":"2023-07-22T11:45:12.341204Z","shell.execute_reply.started":"2023-07-22T11:45:12.330404Z","shell.execute_reply":"2023-07-22T11:45:12.340087Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'attention_mask', 'word_ids'])"},"metadata":{}}]},{"cell_type":"code","source":"sum([[1, 2, 3, 4, 5], [6, 7, 8]], [])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.349410Z","iopub.execute_input":"2023-07-22T11:45:12.350148Z","iopub.status.idle":"2023-07-22T11:45:12.357367Z","shell.execute_reply.started":"2023-07-22T11:45:12.350116Z","shell.execute_reply":"2023-07-22T11:45:12.356075Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[1, 2, 3, 4, 5, 6, 7, 8]"},"metadata":{}}]},{"cell_type":"code","source":"concatenate_example = {i: sum(samples[i], []) for i in samples.keys()}","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.359061Z","iopub.execute_input":"2023-07-22T11:45:12.359843Z","iopub.status.idle":"2023-07-22T11:45:12.366696Z","shell.execute_reply.started":"2023-07-22T11:45:12.359807Z","shell.execute_reply":"2023-07-22T11:45:12.365765Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"length = len(concatenate_example['input_ids'])\nlength","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.368319Z","iopub.execute_input":"2023-07-22T11:45:12.369158Z","iopub.status.idle":"2023-07-22T11:45:12.380051Z","shell.execute_reply.started":"2023-07-22T11:45:12.369121Z","shell.execute_reply":"2023-07-22T11:45:12.379033Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"800"},"metadata":{}}]},{"cell_type":"code","source":"len(concatenate_example)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.381516Z","iopub.execute_input":"2023-07-22T11:45:12.382264Z","iopub.status.idle":"2023-07-22T11:45:12.390901Z","shell.execute_reply.started":"2023-07-22T11:45:12.382145Z","shell.execute_reply":"2023-07-22T11:45:12.389844Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"list(range(0, 10, 2))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.392437Z","iopub.execute_input":"2023-07-22T11:45:12.393130Z","iopub.status.idle":"2023-07-22T11:45:12.402370Z","shell.execute_reply.started":"2023-07-22T11:45:12.393098Z","shell.execute_reply":"2023-07-22T11:45:12.401330Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"[0, 2, 4, 6, 8]"},"metadata":{}}]},{"cell_type":"code","source":"chunk = {\n    key: [item[i: i + chunk_size] for i in range(0, length, chunk_size)] \n    for key, item in concatenate_example.items()\n}","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.403966Z","iopub.execute_input":"2023-07-22T11:45:12.404651Z","iopub.status.idle":"2023-07-22T11:45:12.412168Z","shell.execute_reply.started":"2023-07-22T11:45:12.404617Z","shell.execute_reply":"2023-07-22T11:45:12.411187Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"len(chunk['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.413252Z","iopub.execute_input":"2023-07-22T11:45:12.413568Z","iopub.status.idle":"2023-07-22T11:45:12.427044Z","shell.execute_reply.started":"2023-07-22T11:45:12.413545Z","shell.execute_reply":"2023-07-22T11:45:12.426093Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"7"},"metadata":{}}]},{"cell_type":"code","source":"for i in chunk['input_ids']:\n    print(len(i))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.428273Z","iopub.execute_input":"2023-07-22T11:45:12.428753Z","iopub.status.idle":"2023-07-22T11:45:12.435640Z","shell.execute_reply.started":"2023-07-22T11:45:12.428722Z","shell.execute_reply":"2023-07-22T11:45:12.434528Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"128\n128\n128\n128\n128\n128\n32\n","output_type":"stream"}]},{"cell_type":"code","source":"(length // chunk_size) * chunk_size","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.436838Z","iopub.execute_input":"2023-07-22T11:45:12.437353Z","iopub.status.idle":"2023-07-22T11:45:12.451774Z","shell.execute_reply.started":"2023-07-22T11:45:12.437320Z","shell.execute_reply":"2023-07-22T11:45:12.450734Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"768"},"metadata":{}}]},{"cell_type":"code","source":"def group_texts(examples):\n    concatenate_examples = {i: sum(examples[i], []) for i in examples.keys()}\n    total_length = len(concatenate_examples['input_ids'])\n    total_length = (total_length // chunk_size) * chunk_size\n    chunks = {key: [item[i: i + chunk_size] for i in range(0, total_length, chunk_size)] for key, item in concatenate_examples.items()}\n    chunks['labels'] = chunks['input_ids'].copy()\n    return chunks","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.453046Z","iopub.execute_input":"2023-07-22T11:45:12.454211Z","iopub.status.idle":"2023-07-22T11:45:12.461922Z","shell.execute_reply.started":"2023-07-22T11:45:12.454177Z","shell.execute_reply":"2023-07-22T11:45:12.461120Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"lm_datasets = tokenize_dataset.map(group_texts, batched = True)\nlm_datasets","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:45:12.463096Z","iopub.execute_input":"2023-07-22T11:45:12.464062Z","iopub.status.idle":"2023-07-22T11:51:00.956933Z","shell.execute_reply.started":"2023-07-22T11:45:12.464005Z","shell.execute_reply":"2023-07-22T11:51:00.956041Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40d2303d5d224c33afef7e7aa264e32f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e35f9db3b9c4d978bd2a9778a699274"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2a8f29d3824fdab64899d291dc462c"}},"metadata":{}},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 61291\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 59904\n    })\n    unsupervised: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 122957\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import collections\nimport numpy as np\nfrom transformers import default_data_collator\n\nwwm_probability = 0.2\n\n\ndef whole_word_masking_data_collator(features):\n    for feature in features:\n        word_ids = feature.pop(\"word_ids\")\n\n        # Create a map between words and corresponding token indices\n        mapping = collections.defaultdict(list)\n        current_word_index = -1\n        current_word = None\n        for idx, word_id in enumerate(word_ids):\n            if word_id is not None:\n                if word_id != current_word:\n                    current_word = word_id\n                    current_word_index += 1\n                mapping[current_word_index].append(idx)\n\n        # Randomly mask words\n        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n        input_ids = feature[\"input_ids\"]\n        labels = feature[\"labels\"]\n        new_labels = [-100] * len(labels)\n        for word_id in np.where(mask)[0]:\n            word_id = word_id.item()\n            for idx in mapping[word_id]:\n                new_labels[idx] = labels[idx]\n                input_ids[idx] = tokenizer.mask_token_id\n        feature[\"labels\"] = new_labels\n\n    return default_data_collator(features)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:00.958511Z","iopub.execute_input":"2023-07-22T11:51:00.959154Z","iopub.status.idle":"2023-07-22T11:51:01.336764Z","shell.execute_reply.started":"2023-07-22T11:51:00.959120Z","shell.execute_reply":"2023-07-22T11:51:01.335708Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"samples = [lm_datasets['train'][i] for i in range(2)]\nlen(samples)\n\nbatch = whole_word_masking_data_collator(samples)\n\nfor i in batch['input_ids']:\n    print(tokenizer.decode(i))","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:01.338407Z","iopub.execute_input":"2023-07-22T11:51:01.338763Z","iopub.status.idle":"2023-07-22T11:51:01.350475Z","shell.execute_reply.started":"2023-07-22T11:51:01.338729Z","shell.execute_reply":"2023-07-22T11:51:01.349251Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"[CLS] i [MASK] i am [MASK] - yellow from my video [MASK] because of [MASK] the controversy that surrounded [MASK] when [MASK] was first released in 1967. i also heard that at [MASK] it was [MASK] by u [MASK] s. [MASK] if it [MASK] tried to enter this [MASK], therefore being [MASK] fan of films considered \" controversial \" i [MASK] had to see [MASK] for myself. < br / > < br / > [MASK] plot is centered around a young swedish drama student named lena who wants to [MASK] [MASK] she [MASK] about life. in particular she wants to focus her attentions to making some [MASK] of documentary on what the average swede thought about certain political issues [MASK]\nas the vietnam [MASK] and race issues in the united states [MASK] in between asking politicians and ordinary denizens of stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and [MASK] men. < br / > < br / > what kills me about i am curious - [MASK] is that 40 years ago, this was considered pornographic [MASK] really, the [MASK] and nudity [MASK] are [MASK] and far between, even then it's not shot [MASK] some cheaply [MASK] porno. while my countrymen mind [MASK] it shocking [MASK] [MASK] reality sex [MASK] nudity are a major staple in [MASK] cinema [MASK] even ingmar bergman,\n","output_type":"stream"}]},{"cell_type":"code","source":"lm_datasets","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:01.352200Z","iopub.execute_input":"2023-07-22T11:51:01.352592Z","iopub.status.idle":"2023-07-22T11:51:01.359579Z","shell.execute_reply.started":"2023-07-22T11:51:01.352560Z","shell.execute_reply":"2023-07-22T11:51:01.358480Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 61291\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 59904\n    })\n    unsupervised: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 122957\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_size = 10000\ntest_size = int(0.2 * train_size)\ntrain_size, test_size","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:01.361546Z","iopub.execute_input":"2023-07-22T11:51:01.361935Z","iopub.status.idle":"2023-07-22T11:51:01.371170Z","shell.execute_reply.started":"2023-07-22T11:51:01.361904Z","shell.execute_reply":"2023-07-22T11:51:01.370166Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(10000, 2000)"},"metadata":{}}]},{"cell_type":"code","source":"downsampled_dataset = lm_datasets['train'].train_test_split(train_size=train_size, test_size = test_size, seed = 42)\ndownsampled_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:01.372568Z","iopub.execute_input":"2023-07-22T11:51:01.373140Z","iopub.status.idle":"2023-07-22T11:51:01.401986Z","shell.execute_reply.started":"2023-07-22T11:51:01.373107Z","shell.execute_reply":"2023-07-22T11:51:01.400974Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 10000\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:01.403313Z","iopub.execute_input":"2023-07-22T11:51:01.403660Z","iopub.status.idle":"2023-07-22T11:51:01.456734Z","shell.execute_reply.started":"2023-07-22T11:51:01.403628Z","shell.execute_reply":"2023-07-22T11:51:01.454001Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"bs = 64\nlogging_steps = len(downsampled_dataset['train']) // bs\nargs = TrainingArguments(\n    output_dir=f\"{model_nm}-finetuned-imdb\",\n    overwrite_output_dir=True,\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    per_device_train_batch_size=bs,\n    per_device_eval_batch_size=bs,\n    fp16=True,\n    logging_steps=logging_steps,\n    remove_unused_columns = False,\n    report_to = 'none',\n    push_to_hub = True,\n    num_train_epochs=10\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T13:28:05.142143Z","iopub.execute_input":"2023-07-22T13:28:05.142531Z","iopub.status.idle":"2023-07-22T13:28:05.148854Z","shell.execute_reply.started":"2023-07-22T13:28:05.142500Z","shell.execute_reply":"2023-07-22T13:28:05.148058Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForWholeWordMask","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:01.532709Z","iopub.execute_input":"2023-07-22T11:51:01.533116Z","iopub.status.idle":"2023-07-22T11:51:01.539406Z","shell.execute_reply.started":"2023-07-22T11:51:01.533080Z","shell.execute_reply":"2023-07-22T11:51:01.538200Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForWholeWordMask(tokenizer = tokenizer, mlm_probability = 0.15)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:01.540900Z","iopub.execute_input":"2023-07-22T11:51:01.541418Z","iopub.status.idle":"2023-07-22T11:51:01.550561Z","shell.execute_reply.started":"2023-07-22T11:51:01.541384Z","shell.execute_reply":"2023-07-22T11:51:01.549514Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"test = data_collator([downsampled_dataset['train'][0]['input_ids']])\ntest","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:01.551780Z","iopub.execute_input":"2023-07-22T11:51:01.552683Z","iopub.status.idle":"2023-07-22T11:51:01.571729Z","shell.execute_reply.started":"2023-07-22T11:51:01.552649Z","shell.execute_reply":"2023-07-22T11:51:01.570866Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:951: UserWarning: DataCollatorForWholeWordMask is only suitable for BertTokenizer-like tokenizers. Please refer to the documentation for more information.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[ 1010,   103,   103,  2035,  2017,  2963,  2005,  2019,  3178,   103,\n           1037,  2431,  2003,   103,  2152,  1011,  8219,  1059, 14014,  2183,\n           2006,  2055,  2129,  2010,  4331,  2024,  2190,  1010,  2030,  2054,\n          21864, 15952,  3538,   103,  2759,  3226,  2003, 16356,  2989,  2010,\n          11281,  2012,   103,  2617,  1012,  2002,  2036,  4858,  2051,   103,\n          22889,  8490,  2125,  3152,  2008, 13886,  2987,  1005,   103,  2066,\n           1010,  2242,   103,  2245,  2001,  9235,  2005, 23160,  2066,  2033,\n           1012,  7543,  2108,  1999,  1037,  2597,  2066,  2010,  2017,  1005,\n           1040,  2228,   103,  1005,  1040,  3046,   103,  2191,  1037,  2391,\n           2055,  5988,  1037,   103,  2062,  9414,  2135,  2084,  2023,  1012,\n           2011,  2437,   103,  5372,  2143,  3383,  1010,  2028,  2007,  2070,\n           4784,  1998,  1037, 11519,  3252,   103,  2030,   103,  2028,  2008,\n           3475,  1005,  1056,  6390,  6817,   103,   103, 15703]]),\n 'labels': tensor([[-100, 2061, 2008, -100, -100, -100, -100, -100, -100, 1998, -100, -100,\n          -100, 1037, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n          -100, -100, -100, -100, -100, -100, -100, -100, -100, 1997, -100, -100,\n          -100, -100, -100, -100, -100, -100, 1996, -100, -100, -100, -100, -100,\n          -100, 2000, -100, -100, -100, -100, -100, 2002, -100, -100, 1056, -100,\n          -100, -100, 1045, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2002, -100,\n          -100, -100, 1998, -100, -100, -100, -100, -100, -100, 2210, -100, -100,\n          -100, -100, -100, -100, -100, -100, 1037, -100, -100, -100, -100, -100,\n          -100, -100, -100, -100, -100, -100, -100, 1010, -100, 2672, -100, -100,\n          -100, -100, -100, 3294, -100, 2011, 2010, -100]])}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(test['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:51:01.572896Z","iopub.execute_input":"2023-07-22T11:51:01.573777Z","iopub.status.idle":"2023-07-22T11:51:01.580599Z","shell.execute_reply.started":"2023-07-22T11:51:01.573745Z","shell.execute_reply":"2023-07-22T11:51:01.579575Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"\", [MASK] [MASK] all you hear for an hour [MASK] a half is [MASK] high - pitched whine going on about how his politics are best, or what quirky piece [MASK] popular culture is tickling his fancy at [MASK] moment. he also finds time [MASK] slag off films that clicked doesn'[MASK] like, something [MASK] thought was reserved for losers like me. surely being in a position like his you'd think [MASK]'d try [MASK] make a point about cinema a [MASK] more intelligently than this. by making [MASK] proper film perhaps, one with some ideas and a decent structure [MASK] or [MASK] one that isn't 71 dominated [MASK] [MASK] annoying\""},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode([2061, 2008])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:07:58.225982Z","iopub.execute_input":"2023-07-22T12:07:58.227007Z","iopub.status.idle":"2023-07-22T12:07:58.233656Z","shell.execute_reply.started":"2023-07-22T12:07:58.226973Z","shell.execute_reply":"2023-07-22T12:07:58.232634Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"'so that'"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:09:57.906477Z","iopub.execute_input":"2023-07-22T12:09:57.906845Z","iopub.status.idle":"2023-07-22T12:09:57.928314Z","shell.execute_reply.started":"2023-07-22T12:09:57.906811Z","shell.execute_reply":"2023-07-22T12:09:57.927487Z"},"trusted":true},"execution_count":77,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76aa825660cc4d4693354c19bb90674c"}},"metadata":{}}]},{"cell_type":"code","source":"trainer = Trainer(\n    model = model,\n    args = args,\n    train_dataset= downsampled_dataset['train'],\n    eval_dataset = downsampled_dataset['test'],\n    data_collator= data_collator,\n    tokenizer = tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T13:28:19.807118Z","iopub.execute_input":"2023-07-22T13:28:19.807509Z","iopub.status.idle":"2023-07-22T13:28:22.422241Z","shell.execute_reply.started":"2023-07-22T13:28:19.807477Z","shell.execute_reply":"2023-07-22T13:28:22.421475Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stderr","text":"/kaggle/working/distilbert-base-uncased-finetuned-imdb is already a clone of https://huggingface.co/Sonali-Behera/distilbert-base-uncased-finetuned-imdb. Make sure you pull the latest changes with `repo.git_pull()`.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T13:28:30.009165Z","iopub.execute_input":"2023-07-22T13:28:30.009528Z","iopub.status.idle":"2023-07-22T13:28:35.768312Z","shell.execute_reply.started":"2023-07-22T13:28:30.009498Z","shell.execute_reply":"2023-07-22T13:28:35.767536Z"},"trusted":true},"execution_count":134,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:951: UserWarning: DataCollatorForWholeWordMask is only suitable for BertTokenizer-like tokenizers. Please refer to the documentation for more information.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='64' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 01:49]\n    </div>\n    "},"metadata":{}},{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 2.682955026626587,\n 'eval_runtime': 5.7538,\n 'eval_samples_per_second': 347.593,\n 'eval_steps_per_second': 5.561}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T13:28:39.583033Z","iopub.execute_input":"2023-07-22T13:28:39.583437Z","iopub.status.idle":"2023-07-22T13:46:06.366796Z","shell.execute_reply.started":"2023-07-22T13:28:39.583406Z","shell.execute_reply":"2023-07-22T13:46:06.366091Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1570' max='1570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1570/1570 17:25, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.554500</td>\n      <td>2.685557</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.611800</td>\n      <td>2.656390</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.660100</td>\n      <td>2.658659</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.675400</td>\n      <td>2.616541</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.658600</td>\n      <td>2.614622</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.632900</td>\n      <td>2.621978</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.628200</td>\n      <td>2.596710</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.628100</td>\n      <td>2.642364</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.607400</td>\n      <td>2.614133</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.606100</td>\n      <td>2.597775</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:951: UserWarning: DataCollatorForWholeWordMask is only suitable for BertTokenizer-like tokenizers. Please refer to the documentation for more information.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:951: UserWarning: DataCollatorForWholeWordMask is only suitable for BertTokenizer-like tokenizers. Please refer to the documentation for more information.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:951: UserWarning: DataCollatorForWholeWordMask is only suitable for BertTokenizer-like tokenizers. Please refer to the documentation for more information.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1570, training_loss=2.6252612788206453, metrics={'train_runtime': 1045.6802, 'train_samples_per_second': 95.632, 'train_steps_per_second': 1.501, 'total_flos': 3314028902400000.0, 'train_loss': 2.6252612788206453, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-07-22T13:47:07.128896Z","iopub.execute_input":"2023-07-22T13:47:07.129876Z","iopub.status.idle":"2023-07-22T13:47:12.887132Z","shell.execute_reply.started":"2023-07-22T13:47:07.129842Z","shell.execute_reply":"2023-07-22T13:47:12.886323Z"},"trusted":true},"execution_count":136,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:05]\n    </div>\n    "},"metadata":{}},{"execution_count":136,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 2.6268422603607178,\n 'eval_runtime': 5.7521,\n 'eval_samples_per_second': 347.697,\n 'eval_steps_per_second': 5.563,\n 'epoch': 10.0}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:56:11.122686Z","iopub.execute_input":"2023-07-22T11:56:11.123075Z","iopub.status.idle":"2023-07-22T11:56:12.787454Z","shell.execute_reply.started":"2023-07-22T11:56:11.123040Z","shell.execute_reply":"2023-07-22T11:56:12.786427Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"len(downsampled_dataset['test'][0])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:56:12.789109Z","iopub.execute_input":"2023-07-22T11:56:12.789489Z","iopub.status.idle":"2023-07-22T11:56:12.801270Z","shell.execute_reply.started":"2023-07-22T11:56:12.789453Z","shell.execute_reply":"2023-07-22T11:56:12.800078Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"code","source":"test1 = tokenizer('This is a great [MASK]')\ntest1['word_ids'] = test1.word_ids()\ntest1","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:56:12.803509Z","iopub.execute_input":"2023-07-22T11:56:12.803923Z","iopub.status.idle":"2023-07-22T11:56:12.813046Z","shell.execute_reply.started":"2023-07-22T11:56:12.803862Z","shell.execute_reply":"2023-07-22T11:56:12.812072Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 2023, 2003, 1037, 2307, 103, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1], 'word_ids': [None, 0, 1, 2, 3, 4, None]}"},"metadata":{}}]},{"cell_type":"code","source":"pred = trainer.predict([downsampled_dataset['test'][0]])\npred","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:03:08.763740Z","iopub.execute_input":"2023-07-22T12:03:08.764134Z","iopub.status.idle":"2023-07-22T12:03:08.804773Z","shell.execute_reply.started":"2023-07-22T12:03:08.764100Z","shell.execute_reply":"2023-07-22T12:03:08.803769Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[[-10.2109375, -10.140625 , -10.2109375, ...,  -9.546875 ,\n          -9.7421875,  -7.171875 ],\n        [ -9.3671875,  -9.359375 ,  -9.3671875, ...,  -7.828125 ,\n          -7.65625  ,  -7.7226562],\n        [-13.3671875, -13.4375   , -13.328125 , ..., -11.0546875,\n         -11.171875 , -10.5703125],\n        ...,\n        [-11.3046875, -11.015625 , -11.078125 , ..., -11.       ,\n         -10.5546875, -10.46875  ],\n        [ -9.9375   ,  -9.8515625,  -9.9375   , ...,  -9.421875 ,\n          -8.953125 ,  -9.234375 ],\n        [ -8.9140625,  -8.6953125,  -8.78125  , ...,  -8.59375  ,\n          -8.59375  ,  -7.2929688]]], dtype=float32), label_ids=array([[1012, 2138, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, 2000, -100, 2004, -100, -100, -100, -100, -100,\n        -100, 2231, -100, -100, -100, 2064, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, 1997, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, 2077, 2009, 2150, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, 1999, -100, -100, -100, -100, -100, 1012, -100, -100, -100,\n        3185, -100, -100, -100, -100, -100, -100, 2029, 2003, 2339, -100,\n        -100, -100, -100, 1999, -100, -100, -100, -100, -100, 2477, -100,\n        -100, 2143, -100, -100, -100, -100, -100]]), metrics={'test_loss': 2.971916675567627, 'test_runtime': 0.0291, 'test_samples_per_second': 34.398, 'test_steps_per_second': 34.398})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message='push trainer with 10 epochs')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T13:47:33.311492Z","iopub.execute_input":"2023-07-22T13:47:33.311858Z","iopub.status.idle":"2023-07-22T13:48:09.134705Z","shell.execute_reply.started":"2023-07-22T13:47:33.311825Z","shell.execute_reply":"2023-07-22T13:48:09.133978Z"},"trusted":true},"execution_count":137,"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload file pytorch_model.bin:   0%|          | 1.00/256M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdce661990a741088e2a97ce2d117546"}},"metadata":{}},{"name":"stderr","text":"To https://huggingface.co/Sonali-Behera/distilbert-base-uncased-finetuned-imdb\n   f5e09e8..843d635  main -> main\n\nTo https://huggingface.co/Sonali-Behera/distilbert-base-uncased-finetuned-imdb\n   843d635..4e7723e  main -> main\n\n","output_type":"stream"},{"execution_count":137,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/Sonali-Behera/distilbert-base-uncased-finetuned-imdb/commit/843d6359712d89a7ed975844a9392d53c68c47cb'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(downsampled_dataset['test'][0]['labels'])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:03:36.375887Z","iopub.execute_input":"2023-07-22T12:03:36.376568Z","iopub.status.idle":"2023-07-22T12:03:36.386291Z","shell.execute_reply.started":"2023-07-22T12:03:36.376536Z","shell.execute_reply":"2023-07-22T12:03:36.385183Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"'. because you got to see them as real characters this makes you like them more as an audience, and makes you more sympathetic to them as totally the victims of the white government, who you can not sympathise with. the singing of the students is correct because we know from accounts that the students in the riot were singing and dancing before it became violent. the clothing of the students in sarafina is very similar to the clothing shown in photos from soweto. they made the movie actually in soweto, which is why it looks very accurate in many parts. all these things make the film more accurate for someone using'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(lm_datasets['train'][10]['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:03:46.901583Z","iopub.execute_input":"2023-07-22T12:03:46.901972Z","iopub.status.idle":"2023-07-22T12:03:46.910504Z","shell.execute_reply.started":"2023-07-22T12:03:46.901940Z","shell.execute_reply":"2023-07-22T12:03:46.909521Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"'scrape to find value in its boring pseudo revolutionary political spewings.. but if it weren\\'t for the censorship scandal, it would have been ignored, then forgotten. < br / > < br / > instead, the \" i am blank, blank \" rhythymed title was repeated endlessly for years as a titilation for porno films ( i am curious, lavender - for gay films, i am curious, black - for blaxploitation films, etc.. ) and every ten years or so the thing rises from the dead, to be viewed by a new generation of suckers who want'"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(downsampled_dataset['train'][1]['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T11:56:12.886477Z","iopub.execute_input":"2023-07-22T11:56:12.886831Z","iopub.status.idle":"2023-07-22T11:56:12.897246Z","shell.execute_reply.started":"2023-07-22T11:56:12.886798Z","shell.execute_reply":"2023-07-22T11:56:12.895934Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"'started thinking this was worthy of a 7, but as the film went on it dropped rapidly to a 4, then earning a 3 after the silliness of the wedding scene. this was about as cold and sterile a movie as i have seen. a terrible waste of a good story. [SEP] [CLS] one thing that astonished me about this film ( and not in a good way ) was that nathan stoltzfus, who seems to pride himself on being the major historian on the topic of the rosenstrasse, was one of the historians working on this film, considering how much of the actual events were altered or disregarded. < br'"},"metadata":{}}]},{"cell_type":"code","source":"pred.predictions[0]","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:04:13.255140Z","iopub.execute_input":"2023-07-22T12:04:13.256511Z","iopub.status.idle":"2023-07-22T12:04:13.264720Z","shell.execute_reply.started":"2023-07-22T12:04:13.256463Z","shell.execute_reply":"2023-07-22T12:04:13.263667Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"array([[-10.2109375, -10.140625 , -10.2109375, ...,  -9.546875 ,\n         -9.7421875,  -7.171875 ],\n       [ -9.3671875,  -9.359375 ,  -9.3671875, ...,  -7.828125 ,\n         -7.65625  ,  -7.7226562],\n       [-13.3671875, -13.4375   , -13.328125 , ..., -11.0546875,\n        -11.171875 , -10.5703125],\n       ...,\n       [-11.3046875, -11.015625 , -11.078125 , ..., -11.       ,\n        -10.5546875, -10.46875  ],\n       [ -9.9375   ,  -9.8515625,  -9.9375   , ...,  -9.421875 ,\n         -8.953125 ,  -9.234375 ],\n       [ -8.9140625,  -8.6953125,  -8.78125  , ...,  -8.59375  ,\n         -8.59375  ,  -7.2929688]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import get_full_repo_name","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:17:06.077959Z","iopub.execute_input":"2023-07-22T12:17:06.078951Z","iopub.status.idle":"2023-07-22T12:17:06.083459Z","shell.execute_reply.started":"2023-07-22T12:17:06.078916Z","shell.execute_reply":"2023-07-22T12:17:06.082713Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"model_name = 'distilbert-base-uncased-finetuned-imdb'\nrepo_name = get_full_repo_name(model_name)\nrepo_name","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:17:55.595718Z","iopub.execute_input":"2023-07-22T12:17:55.596117Z","iopub.status.idle":"2023-07-22T12:17:55.704573Z","shell.execute_reply.started":"2023-07-22T12:17:55.596082Z","shell.execute_reply":"2023-07-22T12:17:55.703832Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"'Sonali-Behera/distilbert-base-uncased-finetuned-imdb'"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import Repository","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:18:17.508686Z","iopub.execute_input":"2023-07-22T12:18:17.509067Z","iopub.status.idle":"2023-07-22T12:18:17.513754Z","shell.execute_reply.started":"2023-07-22T12:18:17.509028Z","shell.execute_reply":"2023-07-22T12:18:17.512786Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"output_dir = model_name\nrepo = Repository(output_dir, clone_from = repo_name)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:19:12.808308Z","iopub.execute_input":"2023-07-22T12:19:12.808666Z","iopub.status.idle":"2023-07-22T12:19:12.992098Z","shell.execute_reply.started":"2023-07-22T12:19:12.808635Z","shell.execute_reply":"2023-07-22T12:19:12.991401Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stderr","text":"/kaggle/working/distilbert-base-uncased-finetuned-imdb is already a clone of https://huggingface.co/Sonali-Behera/distilbert-base-uncased-finetuned-imdb. Make sure you pull the latest changes with `repo.git_pull()`.\n","output_type":"stream"}]},{"cell_type":"code","source":"from accelerate import Accelerator","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:23:44.373763Z","iopub.execute_input":"2023-07-22T12:23:44.374174Z","iopub.status.idle":"2023-07-22T12:23:44.378683Z","shell.execute_reply.started":"2023-07-22T12:23:44.374140Z","shell.execute_reply":"2023-07-22T12:23:44.377506Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:37:37.815618Z","iopub.execute_input":"2023-07-22T12:37:37.816011Z","iopub.status.idle":"2023-07-22T12:37:37.822687Z","shell.execute_reply.started":"2023-07-22T12:37:37.815978Z","shell.execute_reply":"2023-07-22T12:37:37.821976Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"DistilBertForMaskedLM(\n  (activation): GELUActivation()\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n  (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n  (vocab_projector): Linear(in_features=768, out_features=30522, bias=True)\n  (mlm_loss_fct): CrossEntropyLoss()\n)"},"metadata":{}}]},{"cell_type":"code","source":"from torch.optim import AdamW\n\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:27:19.864123Z","iopub.execute_input":"2023-07-22T12:27:19.864930Z","iopub.status.idle":"2023-07-22T12:27:19.870056Z","shell.execute_reply.started":"2023-07-22T12:27:19.864898Z","shell.execute_reply":"2023-07-22T12:27:19.869062Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"accelerator = Accelerator()\nmodel, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n    model, optimizer, downsampled_dataset['train'], downsampled_dataset['test']\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:29:19.801072Z","iopub.execute_input":"2023-07-22T12:29:19.801442Z","iopub.status.idle":"2023-07-22T12:29:19.810171Z","shell.execute_reply.started":"2023-07-22T12:29:19.801412Z","shell.execute_reply":"2023-07-22T12:29:19.809257Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"accelerator.wait_for_everyone()\nunwrapped_model = accelerator.unwrap_model(model)\nunwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\nif accelerator.is_main_process:\n    tokenizer.save_pretrained(output_dir)\n    repo.push_to_hub(\n        commit_message='Testing', blocking=False\n    )","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:36:10.194973Z","iopub.execute_input":"2023-07-22T12:36:10.195367Z","iopub.status.idle":"2023-07-22T12:36:14.744710Z","shell.execute_reply.started":"2023-07-22T12:36:10.195330Z","shell.execute_reply":"2023-07-22T12:36:14.743840Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"masking = pipeline('fill-mask', model = 'Sonali-Behera/distilbert-base-uncased-finetuned-imdb')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:40:00.493095Z","iopub.execute_input":"2023-07-22T12:40:00.493503Z","iopub.status.idle":"2023-07-22T12:40:11.528655Z","shell.execute_reply.started":"2023-07-22T12:40:00.493469Z","shell.execute_reply":"2023-07-22T12:40:11.527529Z"},"trusted":true},"execution_count":94,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"328edddb8f9549f2bbeff8c5cec7a585"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5871bc42c28a4e4cbe0b971781f5d754"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48b28b97336b41a3ab7b265a32350941"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f5b203edc64878a8299a20cb46cbf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46db257bf3d845aa917deda91203bf01"}},"metadata":{}}]},{"cell_type":"code","source":"masking('This is a great [MASK]')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:40:56.809953Z","iopub.execute_input":"2023-07-22T12:40:56.810351Z","iopub.status.idle":"2023-07-22T12:40:56.915215Z","shell.execute_reply.started":"2023-07-22T12:40:56.810320Z","shell.execute_reply":"2023-07-22T12:40:56.914377Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.4412679672241211,\n  'token': 999,\n  'token_str': '!',\n  'sequence': 'this is a great!'},\n {'score': 0.2978465259075165,\n  'token': 1012,\n  'token_str': '.',\n  'sequence': 'this is a great.'},\n {'score': 0.03835844621062279,\n  'token': 2143,\n  'token_str': 'film',\n  'sequence': 'this is a great film'},\n {'score': 0.028337379917502403,\n  'token': 3185,\n  'token_str': 'movie',\n  'sequence': 'this is a great movie'},\n {'score': 0.010450121946632862,\n  'token': 3066,\n  'token_str': 'deal',\n  'sequence': 'this is a great deal'}]"},"metadata":{}}]},{"cell_type":"code","source":"masking('I should buy a [MASK]')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:41:32.365847Z","iopub.execute_input":"2023-07-22T12:41:32.366435Z","iopub.status.idle":"2023-07-22T12:41:32.471604Z","shell.execute_reply.started":"2023-07-22T12:41:32.366393Z","shell.execute_reply":"2023-07-22T12:41:32.470789Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.3545718193054199,\n  'token': 1012,\n  'token_str': '.',\n  'sequence': 'i should buy a.'},\n {'score': 0.049423087388277054,\n  'token': 999,\n  'token_str': '!',\n  'sequence': 'i should buy a!'},\n {'score': 0.04307328909635544,\n  'token': 4966,\n  'token_str': 'dvd',\n  'sequence': 'i should buy a dvd'},\n {'score': 0.033906590193510056,\n  'token': 6100,\n  'token_str': 'copy',\n  'sequence': 'i should buy a copy'},\n {'score': 0.030957302078604698,\n  'token': 7281,\n  'token_str': 'ticket',\n  'sequence': 'i should buy a ticket'}]"},"metadata":{}}]},{"cell_type":"code","source":"def insert_random_mask(batch):\n    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n    masked_inputs = data_collator(features)\n    # Create a new \"masked\" column for each column in the dataset\n    return {\"masked_\" + k: v.numpy() for k, v in masked_inputs.items()}","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:44:10.889068Z","iopub.execute_input":"2023-07-22T12:44:10.890209Z","iopub.status.idle":"2023-07-22T12:44:10.895929Z","shell.execute_reply.started":"2023-07-22T12:44:10.890158Z","shell.execute_reply":"2023-07-22T12:44:10.895090Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"samples = [downsampled_dataset['test'][i] for i in range(2)]","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:47:49.565653Z","iopub.execute_input":"2023-07-22T12:47:49.566042Z","iopub.status.idle":"2023-07-22T12:47:49.571934Z","shell.execute_reply.started":"2023-07-22T12:47:49.565992Z","shell.execute_reply":"2023-07-22T12:47:49.570949Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"samples.map(insert_random_mask)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:47:58.075336Z","iopub.execute_input":"2023-07-22T12:47:58.075722Z","iopub.status.idle":"2023-07-22T12:47:58.129228Z","shell.execute_reply.started":"2023-07-22T12:47:58.075693Z","shell.execute_reply":"2023-07-22T12:47:58.128076Z"},"trusted":true},"execution_count":109,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 samples.map(insert_random_mask)                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'list'\u001b[0m object has no attribute \u001b[32m'map'\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 samples.map(insert_random_mask)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'list'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'map'</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(downsampled_dataset['test'][0]['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:51:18.414996Z","iopub.execute_input":"2023-07-22T12:51:18.415398Z","iopub.status.idle":"2023-07-22T12:51:18.424145Z","shell.execute_reply.started":"2023-07-22T12:51:18.415360Z","shell.execute_reply":"2023-07-22T12:51:18.423353Z"},"trusted":true},"execution_count":116,"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"'. because you got to see them as real characters this makes you like them more as an audience, and makes you more sympathetic to them as totally the victims of the white government, who you can not sympathise with. the singing of the students is correct because we know from accounts that the students in the riot were singing and dancing before it became violent. the clothing of the students in sarafina is very similar to the clothing shown in photos from soweto. they made the movie actually in soweto, which is why it looks very accurate in many parts. all these things make the film more accurate for someone using'"},"metadata":{}}]},{"cell_type":"code","source":"masking('ecause you got to see them as real characters this makes you like them more as an [MASK]')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:51:35.396952Z","iopub.execute_input":"2023-07-22T12:51:35.397633Z","iopub.status.idle":"2023-07-22T12:51:35.512669Z","shell.execute_reply.started":"2023-07-22T12:51:35.397601Z","shell.execute_reply":"2023-07-22T12:51:35.511945Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.25816231966018677,\n  'token': 1012,\n  'token_str': '.',\n  'sequence': 'ecause you got to see them as real characters this makes you like them more as an.'},\n {'score': 0.14795410633087158,\n  'token': 3364,\n  'token_str': 'actor',\n  'sequence': 'ecause you got to see them as real characters this makes you like them more as an actor'},\n {'score': 0.0428636372089386,\n  'token': 3883,\n  'token_str': 'actress',\n  'sequence': 'ecause you got to see them as real characters this makes you like them more as an actress'},\n {'score': 0.030408352613449097,\n  'token': 21751,\n  'token_str': 'entertainer',\n  'sequence': 'ecause you got to see them as real characters this makes you like them more as an entertainer'},\n {'score': 0.027762606739997864,\n  'token': 3265,\n  'token_str': 'individual',\n  'sequence': 'ecause you got to see them as real characters this makes you like them more as an individual'}]"},"metadata":{}}]},{"cell_type":"code","source":"masking('they made the movie actually in [MASK]')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:52:02.896802Z","iopub.execute_input":"2023-07-22T12:52:02.900138Z","iopub.status.idle":"2023-07-22T12:52:03.009666Z","shell.execute_reply.started":"2023-07-22T12:52:02.900099Z","shell.execute_reply":"2023-07-22T12:52:03.008914Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.44295230507850647,\n  'token': 1012,\n  'token_str': '.',\n  'sequence': 'they made the movie actually in.'},\n {'score': 0.032563161104917526,\n  'token': 1025,\n  'token_str': ';',\n  'sequence': 'they made the movie actually in ;'},\n {'score': 0.024662215262651443,\n  'token': 1029,\n  'token_str': '?',\n  'sequence': 'they made the movie actually in?'},\n {'score': 0.023442735895514488,\n  'token': 999,\n  'token_str': '!',\n  'sequence': 'they made the movie actually in!'},\n {'score': 0.008598772808909416,\n  'token': 2605,\n  'token_str': 'france',\n  'sequence': 'they made the movie actually in france'}]"},"metadata":{}}]},{"cell_type":"code","source":"masking('the singing of the students is correct [MASK] we know from accounts that')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:53:34.674993Z","iopub.execute_input":"2023-07-22T12:53:34.675397Z","iopub.status.idle":"2023-07-22T12:53:34.815868Z","shell.execute_reply.started":"2023-07-22T12:53:34.675362Z","shell.execute_reply":"2023-07-22T12:53:34.815079Z"},"trusted":true},"execution_count":120,"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.33871564269065857,\n  'token': 1012,\n  'token_str': '.',\n  'sequence': 'the singing of the students is correct. we know from accounts that'},\n {'score': 0.18737328052520752,\n  'token': 1998,\n  'token_str': 'and',\n  'sequence': 'the singing of the students is correct and we know from accounts that'},\n {'score': 0.09713467210531235,\n  'token': 1010,\n  'token_str': ',',\n  'sequence': 'the singing of the students is correct, we know from accounts that'},\n {'score': 0.07213137298822403,\n  'token': 2021,\n  'token_str': 'but',\n  'sequence': 'the singing of the students is correct but we know from accounts that'},\n {'score': 0.06839676201343536,\n  'token': 2004,\n  'token_str': 'as',\n  'sequence': 'the singing of the students is correct as we know from accounts that'}]"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(downsampled_dataset['test'][45]['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:53:59.801741Z","iopub.execute_input":"2023-07-22T12:53:59.802169Z","iopub.status.idle":"2023-07-22T12:53:59.811114Z","shell.execute_reply.started":"2023-07-22T12:53:59.802136Z","shell.execute_reply":"2023-07-22T12:53:59.810319Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"'concept is not without merit. < br / > < br / > we are left wondering why a loving couple - a father and son no less - should be so estranged from the real world that their own world is preferable when claustrophobic beyond all imagining. this loss of presence in the real world is, rather too obviously and unnecessarily, contrasted with the son having enlisted in the armed forces. why not the circus, so we can at least appreciate some colour? we are left with a gnawing sense of loss, but sadly no enlightenment, which is bewildering given the film is apparently about some'"},"metadata":{}}]},{"cell_type":"code","source":"masking('we are left with a [MASK] sense of loss, but sadly no enlightenment')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:54:32.566985Z","iopub.execute_input":"2023-07-22T12:54:32.567890Z","iopub.status.idle":"2023-07-22T12:54:32.644815Z","shell.execute_reply.started":"2023-07-22T12:54:32.567827Z","shell.execute_reply":"2023-07-22T12:54:32.644069Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.15367326140403748,\n  'token': 13769,\n  'token_str': 'profound',\n  'sequence': 'we are left with a profound sense of loss, but sadly no enlightenment'},\n {'score': 0.10520612448453903,\n  'token': 2784,\n  'token_str': 'deep',\n  'sequence': 'we are left with a deep sense of loss, but sadly no enlightenment'},\n {'score': 0.05755991488695145,\n  'token': 2307,\n  'token_str': 'great',\n  'sequence': 'we are left with a great sense of loss, but sadly no enlightenment'},\n {'score': 0.04250901937484741,\n  'token': 2844,\n  'token_str': 'strong',\n  'sequence': 'we are left with a strong sense of loss, but sadly no enlightenment'},\n {'score': 0.041556466370821,\n  'token': 3056,\n  'token_str': 'certain',\n  'sequence': 'we are left with a certain sense of loss, but sadly no enlightenment'}]"},"metadata":{}}]},{"cell_type":"code","source":"masking('a [MASK] and son no less - should be so estranged from the real world that their own world is preferable when claustrophobic beyond all imagining')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:55:10.553326Z","iopub.execute_input":"2023-07-22T12:55:10.553702Z","iopub.status.idle":"2023-07-22T12:55:10.650104Z","shell.execute_reply.started":"2023-07-22T12:55:10.553673Z","shell.execute_reply":"2023-07-22T12:55:10.649370Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.4670730531215668,\n  'token': 2388,\n  'token_str': 'mother',\n  'sequence': 'a mother and son no less - should be so estranged from the real world that their own world is preferable when claustrophobic beyond all imagining'},\n {'score': 0.2596692144870758,\n  'token': 2269,\n  'token_str': 'father',\n  'sequence': 'a father and son no less - should be so estranged from the real world that their own world is preferable when claustrophobic beyond all imagining'},\n {'score': 0.16834187507629395,\n  'token': 2564,\n  'token_str': 'wife',\n  'sequence': 'a wife and son no less - should be so estranged from the real world that their own world is preferable when claustrophobic beyond all imagining'},\n {'score': 0.029327429831027985,\n  'token': 3129,\n  'token_str': 'husband',\n  'sequence': 'a husband and son no less - should be so estranged from the real world that their own world is preferable when claustrophobic beyond all imagining'},\n {'score': 0.02290317229926586,\n  'token': 2684,\n  'token_str': 'daughter',\n  'sequence': 'a daughter and son no less - should be so estranged from the real world that their own world is preferable when claustrophobic beyond all imagining'}]"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(downsampled_dataset['test'][98]['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:56:01.648469Z","iopub.execute_input":"2023-07-22T12:56:01.648866Z","iopub.status.idle":"2023-07-22T12:56:01.659742Z","shell.execute_reply.started":"2023-07-22T12:56:01.648823Z","shell.execute_reply":"2023-07-22T12:56:01.658824Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"'that 50 % of a good film is the music and though i\\'m not certain i think the title theme was a simple but moving clarinet solo of \" what a friend we have in jesus \". the film then went on to disprove that! am i right or wrong? [SEP] [CLS] i saw this 25 years ago on pbs. it was very difficult to watch. so real. to watch this small family struggle in the winter was heart rending. no time for courting : fate has thrown us together and we put our shoulders to the grindstone and make it work. this was based on the woman\\'s actual diary,'"},"metadata":{}}]},{"cell_type":"code","source":"masking('i saw this [MASK] years ago on pbs')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:56:36.713929Z","iopub.execute_input":"2023-07-22T12:56:36.715011Z","iopub.status.idle":"2023-07-22T12:56:36.857932Z","shell.execute_reply.started":"2023-07-22T12:56:36.714974Z","shell.execute_reply":"2023-07-22T12:56:36.857200Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.11962835490703583,\n  'token': 2184,\n  'token_str': '10',\n  'sequence': 'i saw this 10 years ago on pbs'},\n {'score': 0.06810285896062851,\n  'token': 2048,\n  'token_str': 'two',\n  'sequence': 'i saw this two years ago on pbs'},\n {'score': 0.06252306699752808,\n  'token': 2322,\n  'token_str': '20',\n  'sequence': 'i saw this 20 years ago on pbs'},\n {'score': 0.048727065324783325,\n  'token': 1016,\n  'token_str': '2',\n  'sequence': 'i saw this 2 years ago on pbs'},\n {'score': 0.03928649052977562,\n  'token': 2382,\n  'token_str': '30',\n  'sequence': 'i saw this 30 years ago on pbs'}]"},"metadata":{}}]},{"cell_type":"code","source":"masking('this was based on the [MASK]\\'s actual diary')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:57:31.200355Z","iopub.execute_input":"2023-07-22T12:57:31.200796Z","iopub.status.idle":"2023-07-22T12:57:31.330411Z","shell.execute_reply.started":"2023-07-22T12:57:31.200760Z","shell.execute_reply":"2023-07-22T12:57:31.329673Z"},"trusted":true},"execution_count":127,"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.1298181265592575,\n  'token': 3166,\n  'token_str': 'author',\n  'sequence': \"this was based on the author's actual diary\"},\n {'score': 0.11708644777536392,\n  'token': 2143,\n  'token_str': 'film',\n  'sequence': \"this was based on the film's actual diary\"},\n {'score': 0.05739942938089371,\n  'token': 2839,\n  'token_str': 'character',\n  'sequence': \"this was based on the character's actual diary\"},\n {'score': 0.03526931628584862,\n  'token': 3213,\n  'token_str': 'writer',\n  'sequence': \"this was based on the writer's actual diary\"},\n {'score': 0.02874480001628399,\n  'token': 3185,\n  'token_str': 'movie',\n  'sequence': \"this was based on the movie's actual diary\"}]"},"metadata":{}}]},{"cell_type":"code","source":"masking('what is your [MASK]')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:59:16.907155Z","iopub.execute_input":"2023-07-22T12:59:16.907521Z","iopub.status.idle":"2023-07-22T12:59:16.986155Z","shell.execute_reply.started":"2023-07-22T12:59:16.907490Z","shell.execute_reply":"2023-07-22T12:59:16.985423Z"},"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.8263999819755554,\n  'token': 1029,\n  'token_str': '?',\n  'sequence': 'what is your?'},\n {'score': 0.03628050908446312,\n  'token': 1012,\n  'token_str': '.',\n  'sequence': 'what is your.'},\n {'score': 0.017996083945035934,\n  'token': 2171,\n  'token_str': 'name',\n  'sequence': 'what is your name'},\n {'score': 0.014039468951523304,\n  'token': 999,\n  'token_str': '!',\n  'sequence': 'what is your!'},\n {'score': 0.004874095320701599,\n  'token': 2166,\n  'token_str': 'life',\n  'sequence': 'what is your life'}]"},"metadata":{}}]},{"cell_type":"code","source":"masking('the movie is full of [MASK]')","metadata":{"execution":{"iopub.status.busy":"2023-07-22T12:59:44.650792Z","iopub.execute_input":"2023-07-22T12:59:44.651210Z","iopub.status.idle":"2023-07-22T12:59:44.756141Z","shell.execute_reply.started":"2023-07-22T12:59:44.651178Z","shell.execute_reply":"2023-07-22T12:59:44.755286Z"},"trusted":true},"execution_count":130,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.46089789271354675,\n  'token': 1012,\n  'token_str': '.',\n  'sequence': 'the movie is full of.'},\n {'score': 0.04534144699573517,\n  'token': 20096,\n  'token_str': 'surprises',\n  'sequence': 'the movie is full of surprises'},\n {'score': 0.02637871541082859,\n  'token': 4569,\n  'token_str': 'fun',\n  'sequence': 'the movie is full of fun'},\n {'score': 0.02590741403400898,\n  'token': 999,\n  'token_str': '!',\n  'sequence': 'the movie is full of!'},\n {'score': 0.011840630322694778,\n  'token': 4933,\n  'token_str': 'stuff',\n  'sequence': 'the movie is full of stuff'}]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}